{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWdQV13_JD0q"
      },
      "outputs": [],
      "source": [
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51E_WhRqL9zY"
      },
      "outputs": [],
      "source": [
        "def load_data_from_mat(file_path, key):\n",
        "    data = loadmat(file_path)\n",
        "    return data[key]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nXB-bdwK3Zw"
      },
      "outputs": [],
      "source": [
        "# Define paths and keys for each class\n",
        "file_info_dict = {\n",
        "    'A': [('/content/drive/MyDrive/emdvmd/EMDF.mat', 'IMFemd1F')],\n",
        "    'B': [('/content/drive/MyDrive/emdvmd/EMDN.mat', 'IMFemd1N')],\n",
        "    'C': [('/content/drive/MyDrive/emdvmd/EMDO.mat', 'IMFemd1O')],\n",
        "    'D': [('/content/drive/MyDrive/emdvmd/EMDS.mat', 'IMFemd1S')],\n",
        "    'E': [('/content/drive/MyDrive/emdvmd/EMDZ.mat', 'IMFemd1Z')]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3w6olgLBkJu"
      },
      "outputs": [],
      "source": [
        "def prepare_data_for_classification(classes):\n",
        "    X, y = [], []\n",
        "    for label, class_id in enumerate(classes):\n",
        "        file_info = file_info_dict[class_id]  # Get file paths and keys for each class\n",
        "        for file_path, key in file_info:\n",
        "            data = load_data_from_mat(file_path, key)\n",
        "            X.append(data)\n",
        "            y.append(np.array([label] * data.shape[0]))  # Assign the same label to all samples\n",
        "    X = np.concatenate(X)\n",
        "    y = np.concatenate(y)\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lR5O4C1Gq_nB"
      },
      "outputs": [],
      "source": [
        "# Define model creation function\n",
        "def create_cnn_lstm_model(input_shape, filters, kernel_size, pool_size, lstm_units1, lstm_units2, output_units):\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling1D(pool_size=pool_size))\n",
        "    model.add(LSTM(units=lstm_units1, return_sequences=True))\n",
        "    model.add(LSTM(units=lstm_units2))\n",
        "    model.add(Dense(units=output_units, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN2f8I9BK6jo"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(y_true, y_pred):\n",
        "    y_true = np.argmax(y_true, axis=1)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    sensitivity = recall_score(y_true, y_pred, average='macro')\n",
        "    specificity = recall_score(y_true, y_pred, average='macro', labels=[0, 1])\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    return accuracy, sensitivity, specificity, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uc2EZyN3K-c_"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_cnn_lstm_model(X_train, y_train, X_test, y_test, filters, kernel_size, pool_size, lstm_units1, lstm_units2, batch_size, epochs):\n",
        "    model = create_cnn_lstm_model((X_train.shape[1], 1), filters, kernel_size, pool_size, lstm_units1, lstm_units2, y_train.shape[1])\n",
        "    history = model.fit(X_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "    y_pred = model.predict(X_test)\n",
        "    score = model.evaluate(X_test, y_test, verbose=1)\n",
        "    accuracy, sensitivity, specificity, f1 = compute_metrics(y_test, y_pred)\n",
        "    print(f'Test loss: {score[0]}')\n",
        "    print(f'Test accuracy: {accuracy}')\n",
        "    print(f'Sensitivity (Recall): {sensitivity}')\n",
        "    print(f'Specificity: {specificity}')\n",
        "    print(f'F1 Score: {f1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr1uDppKLKVg"
      },
      "source": [
        "# Classification A-B vs. C-D-E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98AUNNiHK_5f",
        "outputId": "c0b4dd8e-eb5d-42a2-9ff4-d5da3ac47357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 196ms/step - accuracy: 0.8557 - loss: 0.2918 - val_accuracy: 0.9701 - val_loss: 0.0929\n",
            "Epoch 2/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 193ms/step - accuracy: 0.9697 - loss: 0.0829 - val_accuracy: 0.9823 - val_loss: 0.0392\n",
            "Epoch 3/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 193ms/step - accuracy: 0.9822 - loss: 0.0506 - val_accuracy: 0.9893 - val_loss: 0.0290\n",
            "Epoch 4/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 196ms/step - accuracy: 0.9846 - loss: 0.0426 - val_accuracy: 0.9640 - val_loss: 0.1122\n",
            "Epoch 5/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 192ms/step - accuracy: 0.9881 - loss: 0.0391 - val_accuracy: 0.9915 - val_loss: 0.0226\n",
            "Epoch 6/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 207ms/step - accuracy: 0.9903 - loss: 0.0301 - val_accuracy: 0.9927 - val_loss: 0.0187\n",
            "Epoch 7/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 200ms/step - accuracy: 0.9892 - loss: 0.0284 - val_accuracy: 0.9863 - val_loss: 0.0385\n",
            "Epoch 8/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 196ms/step - accuracy: 0.9915 - loss: 0.0238 - val_accuracy: 0.9887 - val_loss: 0.0293\n",
            "Epoch 9/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 190ms/step - accuracy: 0.9945 - loss: 0.0171 - val_accuracy: 0.9576 - val_loss: 0.1019\n",
            "Epoch 10/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 191ms/step - accuracy: 0.9909 - loss: 0.0272 - val_accuracy: 0.9954 - val_loss: 0.0125\n",
            "Epoch 11/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 203ms/step - accuracy: 0.9954 - loss: 0.0143 - val_accuracy: 0.9918 - val_loss: 0.0247\n",
            "Epoch 12/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 189ms/step - accuracy: 0.9944 - loss: 0.0191 - val_accuracy: 0.9969 - val_loss: 0.0124\n",
            "Epoch 13/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 190ms/step - accuracy: 0.9957 - loss: 0.0135 - val_accuracy: 0.9951 - val_loss: 0.0139\n",
            "Epoch 14/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 189ms/step - accuracy: 0.9965 - loss: 0.0135 - val_accuracy: 0.9899 - val_loss: 0.0252\n",
            "Epoch 15/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 197ms/step - accuracy: 0.9957 - loss: 0.0133 - val_accuracy: 0.9960 - val_loss: 0.0139\n",
            "Epoch 16/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 190ms/step - accuracy: 0.9964 - loss: 0.0100 - val_accuracy: 0.9966 - val_loss: 0.0097\n",
            "Epoch 17/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 188ms/step - accuracy: 0.9967 - loss: 0.0113 - val_accuracy: 0.9966 - val_loss: 0.0101\n",
            "Epoch 18/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 199ms/step - accuracy: 0.9969 - loss: 0.0077 - val_accuracy: 0.9881 - val_loss: 0.0365\n",
            "Epoch 19/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 208ms/step - accuracy: 0.9966 - loss: 0.0100 - val_accuracy: 0.9957 - val_loss: 0.0126\n",
            "Epoch 20/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 200ms/step - accuracy: 0.9961 - loss: 0.0108 - val_accuracy: 0.9948 - val_loss: 0.0162\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 78ms/step\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.9951 - loss: 0.0163\n",
            "Test loss: 0.018740782514214516\n",
            "Test accuracy: 0.9941420551623139\n",
            "Sensitivity (Recall): 0.9933796147931743\n",
            "Specificity: 0.9933796147931743\n",
            "F1 Score: 0.9938869146351471\n"
          ]
        }
      ],
      "source": [
        "# Classification A-B vs. C-D-E\n",
        "# Load and preprocess data for classes A-B vs. C-D-E\n",
        "classes_ab = ['A', 'B']\n",
        "classes_cde = ['C', 'D', 'E']\n",
        "\n",
        "X_ab, y_ab = prepare_data_for_classification(classes_ab)\n",
        "X_cde, y_cde = prepare_data_for_classification(classes_cde)\n",
        "\n",
        "# Merge and create new labels\n",
        "X = np.concatenate([X_ab, X_cde])\n",
        "y = np.concatenate([np.zeros(len(y_ab)), np.ones(len(y_cde))])  # 0 for A-B, 1 for C-D-E\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape data for CNN-LSTM\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# Encode labels\n",
        "y = y.astype(int)  # Ensure labels are integers\n",
        "y = np.eye(len(np.unique(y)))[y]  # One-hot encode the labels\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate the CNN-LSTM model\n",
        "train_and_evaluate_cnn_lstm_model(X_train, y_train, X_test, y_test, filters=64, kernel_size=3, pool_size=2, lstm_units1=128, lstm_units2=128, batch_size=32, epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT41AbgfLUN4"
      },
      "source": [
        "# Classification A vs. E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW7YZQlxLUqK",
        "outputId": "c7d2f505-114f-4728-a6a0-6003934e1307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 182ms/step - accuracy: 0.7728 - loss: 0.4117 - val_accuracy: 0.9741 - val_loss: 0.0949\n",
            "Epoch 2/5\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 175ms/step - accuracy: 0.9602 - loss: 0.1058 - val_accuracy: 0.9733 - val_loss: 0.0869\n",
            "Epoch 3/5\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 183ms/step - accuracy: 0.9705 - loss: 0.0784 - val_accuracy: 0.9832 - val_loss: 0.0440\n",
            "Epoch 4/5\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 176ms/step - accuracy: 0.9881 - loss: 0.0335 - val_accuracy: 0.9786 - val_loss: 0.0649\n",
            "Epoch 5/5\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 184ms/step - accuracy: 0.9859 - loss: 0.0409 - val_accuracy: 0.9870 - val_loss: 0.0369\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.9891 - loss: 0.0339\n",
            "Test loss: 0.023321976885199547\n",
            "Test accuracy: 0.9920683343502136\n",
            "Sensitivity (Recall): 0.9921397282317183\n",
            "Specificity: 0.9921397282317183\n",
            "F1 Score: 0.9920645059170772\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data for classes A and E\n",
        "classes_a = ['A']\n",
        "classes_e = ['E']\n",
        "X_a, y_a = prepare_data_for_classification(classes_a)\n",
        "X_e, y_e = prepare_data_for_classification(classes_e)\n",
        "\n",
        "# Merge and create new labels\n",
        "X = np.concatenate([X_a, X_e])\n",
        "y = np.concatenate([np.zeros(len(y_a)), np.ones(len(y_e))])  # 0 for A, 1 for E\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape data for CNN-LSTM\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = np.eye(len(np.unique(y)))[y]  # One-hot encode the labels\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate the CNN-LSTM model\n",
        "train_and_evaluate_cnn_lstm_model(X_train, y_train, X_test, y_test, filters=64, kernel_size=3, pool_size=2, lstm_units1=128, lstm_units2=128, batch_size=32, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq0k5C5nLYMY"
      },
      "source": [
        "# Classification B vs. E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ATOLdK9LaN2",
        "outputId": "98bb42fe-7ddd-4680-cec1-f621239ebf71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 214ms/step - accuracy: 0.8363 - loss: 0.3141 - val_accuracy: 0.9779 - val_loss: 0.0567\n",
            "Epoch 2/5\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 201ms/step - accuracy: 0.9777 - loss: 0.0662 - val_accuracy: 0.9863 - val_loss: 0.0517\n",
            "Epoch 3/5\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 198ms/step - accuracy: 0.9835 - loss: 0.0513 - val_accuracy: 0.9901 - val_loss: 0.0323\n",
            "Epoch 4/5\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 194ms/step - accuracy: 0.9901 - loss: 0.0351 - val_accuracy: 0.9863 - val_loss: 0.0360\n",
            "Epoch 5/5\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 209ms/step - accuracy: 0.9896 - loss: 0.0347 - val_accuracy: 0.9962 - val_loss: 0.0129\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9888 - loss: 0.0308\n",
            "Test loss: 0.029943004250526428\n",
            "Test accuracy: 0.9890176937156803\n",
            "Sensitivity (Recall): 0.9892857142857143\n",
            "Specificity: 0.9892857142857143\n",
            "F1 Score: 0.9890155306144333\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data for classes B and E\n",
        "classes_b = ['B']\n",
        "classes_e = ['E']\n",
        "X_b, y_b = prepare_data_for_classification(classes_b)\n",
        "X_e, y_e = prepare_data_for_classification(classes_e)\n",
        "\n",
        "# Merge and create new labels\n",
        "X = np.concatenate([X_b, X_e])\n",
        "y = np.concatenate([np.zeros(len(y_b)), np.ones(len(y_e))])  # 0 for B, 1 for E\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape data for CNN-LSTM\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = np.eye(len(np.unique(y)))[y]  # One-hot encode the labels\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate the CNN-LSTM model\n",
        "train_and_evaluate_cnn_lstm_model(X_train, y_train, X_test, y_test, filters=64, kernel_size=3, pool_size=2, lstm_units1=128, lstm_units2=128, batch_size=32, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNUG45okLema"
      },
      "source": [
        "# Classification B vs. D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeoOwm4JLfDo",
        "outputId": "7bcb7e0a-81b4-41a3-cc03-e7fd82179e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 178ms/step - accuracy: 0.8936 - loss: 0.1600 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
            "Epoch 2/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 173ms/step - accuracy: 0.9999 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 4.3247e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 173ms/step - accuracy: 1.0000 - loss: 3.5889e-04 - val_accuracy: 1.0000 - val_loss: 1.9385e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 176ms/step - accuracy: 1.0000 - loss: 1.6928e-04 - val_accuracy: 1.0000 - val_loss: 1.1362e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 180ms/step - accuracy: 1.0000 - loss: 1.0605e-04 - val_accuracy: 1.0000 - val_loss: 7.5848e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 183ms/step - accuracy: 1.0000 - loss: 7.2095e-05 - val_accuracy: 1.0000 - val_loss: 5.4260e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 175ms/step - accuracy: 1.0000 - loss: 5.1862e-05 - val_accuracy: 1.0000 - val_loss: 4.0537e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 167ms/step - accuracy: 1.0000 - loss: 3.8077e-05 - val_accuracy: 1.0000 - val_loss: 3.1433e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 172ms/step - accuracy: 1.0000 - loss: 3.0074e-05 - val_accuracy: 1.0000 - val_loss: 2.5136e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 176ms/step - accuracy: 1.0000 - loss: 2.4564e-05 - val_accuracy: 1.0000 - val_loss: 2.0566e-05\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 2.0612e-05\n",
            "Test loss: 2.1343228581827134e-05\n",
            "Test accuracy: 1.0\n",
            "Sensitivity (Recall): 1.0\n",
            "Specificity: 1.0\n",
            "F1 Score: 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load and preprocess data for classes B and D\n",
        "classes_bd = ['B', 'D']\n",
        "X, y = prepare_data_for_classification(classes_bd)\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape data for CNN-LSTM\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = np.eye(len(np.unique(y)))[y]  # One-hot encode the labels\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate the CNN-LSTM model\n",
        "train_and_evaluate_cnn_lstm_model(X_train, y_train, X_test, y_test, filters=64, kernel_size=3, pool_size=2, lstm_units1=128, lstm_units2=128, batch_size=32, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6fOSqIsLiZQ"
      },
      "source": [
        "# Classification A vs. C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fevDcJAqLi9y",
        "outputId": "8747cb8c-ae40-4709-99f6-3339bf8370fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 196ms/step - accuracy: 0.8729 - loss: 0.2246 - val_accuracy: 0.9931 - val_loss: 0.0209\n",
            "Epoch 2/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 211ms/step - accuracy: 0.9921 - loss: 0.0265 - val_accuracy: 0.9954 - val_loss: 0.0121\n",
            "Epoch 3/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 193ms/step - accuracy: 0.9959 - loss: 0.0131 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
            "Epoch 4/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 195ms/step - accuracy: 0.9979 - loss: 0.0089 - val_accuracy: 0.9962 - val_loss: 0.0117\n",
            "Epoch 5/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 194ms/step - accuracy: 0.9960 - loss: 0.0159 - val_accuracy: 1.0000 - val_loss: 5.8139e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 193ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.9977 - val_loss: 0.0040\n",
            "Epoch 7/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 191ms/step - accuracy: 0.9992 - loss: 0.0039 - val_accuracy: 0.9977 - val_loss: 0.0039\n",
            "Epoch 8/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 201ms/step - accuracy: 0.9990 - loss: 0.0058 - val_accuracy: 0.9992 - val_loss: 0.0023\n",
            "Epoch 9/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 196ms/step - accuracy: 0.9985 - loss: 0.0118 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 194ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.9985 - val_loss: 0.0032\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9999 - loss: 0.0014\n",
            "Test loss: 0.0020710753742605448\n",
            "Test accuracy: 0.9993898718730934\n",
            "Sensitivity (Recall): 0.9993742177722152\n",
            "Specificity: 0.9993742177722152\n",
            "F1 Score: 0.9993894709629931\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data for classes A and C\n",
        "classes_ac = ['A']\n",
        "classes_c = ['C']\n",
        "X_a, y_a = prepare_data_for_classification(classes_ac)\n",
        "X_c, y_c = prepare_data_for_classification(classes_c)\n",
        "\n",
        "# Merge and create new labels\n",
        "X = np.concatenate([X_a, X_c])\n",
        "y = np.concatenate([np.zeros(len(y_a)), np.ones(len(y_c))])  # 0 for A, 1 for C\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape data for CNN-LSTM\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = np.eye(len(np.unique(y)))[y]  # One-hot encode the labels\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate the CNN-LSTM model\n",
        "train_and_evaluate_cnn_lstm_model(X_train, y_train, X_test, y_test, filters=64, kernel_size=3, pool_size=2, lstm_units1=128, lstm_units2=128, batch_size=32, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAaKD9GbLmSY"
      },
      "source": [
        "# Classification C vs. E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ8XNAUmLnuK",
        "outputId": "90a62b94-ab4a-4f8e-fb2e-c1df5271c912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 204ms/step - accuracy: 0.8503 - loss: 0.2324 - val_accuracy: 0.9878 - val_loss: 0.0355\n",
            "Epoch 2/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 200ms/step - accuracy: 0.9935 - loss: 0.0237 - val_accuracy: 0.9985 - val_loss: 0.0061\n",
            "Epoch 3/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 202ms/step - accuracy: 0.9939 - loss: 0.0196 - val_accuracy: 0.9977 - val_loss: 0.0047\n",
            "Epoch 4/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 208ms/step - accuracy: 0.9964 - loss: 0.0123 - val_accuracy: 0.9817 - val_loss: 0.0740\n",
            "Epoch 5/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 198ms/step - accuracy: 0.9931 - loss: 0.0228 - val_accuracy: 0.9985 - val_loss: 0.0065\n",
            "Epoch 6/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 196ms/step - accuracy: 0.9939 - loss: 0.0188 - val_accuracy: 0.9954 - val_loss: 0.0141\n",
            "Epoch 7/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 195ms/step - accuracy: 0.9956 - loss: 0.0202 - val_accuracy: 0.9901 - val_loss: 0.0277\n",
            "Epoch 8/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 200ms/step - accuracy: 0.9904 - loss: 0.0245 - val_accuracy: 0.9977 - val_loss: 0.0074\n",
            "Epoch 9/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 196ms/step - accuracy: 0.9960 - loss: 0.0090 - val_accuracy: 0.9969 - val_loss: 0.0175\n",
            "Epoch 10/10\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 198ms/step - accuracy: 0.9962 - loss: 0.0139 - val_accuracy: 0.9985 - val_loss: 0.0045\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9973 - loss: 0.0037\n",
            "Test loss: 0.0024425173178315163\n",
            "Test accuracy: 0.9993898718730934\n",
            "Sensitivity (Recall): 0.9994047619047619\n",
            "Specificity: 0.9994047619047619\n",
            "F1 Score: 0.9993895082580275\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data for classes C and E\n",
        "classes_c = ['C']\n",
        "classes_e = ['E']\n",
        "X_c, y_c = prepare_data_for_classification(classes_c)\n",
        "X_e, y_e = prepare_data_for_classification(classes_e)\n",
        "\n",
        "# Merge and create new labels\n",
        "X = np.concatenate([X_c, X_e])\n",
        "y = np.concatenate([np.zeros(len(y_c)), np.ones(len(y_e))])  # 0 for C, 1 for E\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape data for CNN-LSTM\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = np.eye(len(np.unique(y)))[y]  # One-hot encode the labels\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate the CNN-LSTM model\n",
        "train_and_evaluate_cnn_lstm_model(X_train, y_train, X_test, y_test, filters=64, kernel_size=3, pool_size=2, lstm_units1=128, lstm_units2=128, batch_size=32, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZn-uVIYLwrR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}