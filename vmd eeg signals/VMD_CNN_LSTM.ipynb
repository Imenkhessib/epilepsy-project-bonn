{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bha9WdsXgE36"
      },
      "outputs": [],
      "source": [
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_from_mat(file_path, key):\n",
        "    data = loadmat(file_path)\n",
        "    return data[key]\n"
      ],
      "metadata": {
        "id": "W32NwiL1gNLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths and keys for each class\n",
        "file_info_dict = {\n",
        "    'A': [('/content/drive/MyDrive/emdvmd/VMDF.mat', 'IMFvmd1F')],\n",
        "    'B': [('/content/drive/MyDrive/emdvmd/VMDN.mat', 'IMFvmd1N')],\n",
        "    'C': [('/content/drive/MyDrive/emdvmd/VMDO.mat', 'IMFvmd1O')],\n",
        "    'D': [('/content/drive/MyDrive/emdvmd/VMDS.mat', 'IMFvmd1S')],\n",
        "    'E': [('/content/drive/MyDrive/emdvmd/VMDZ.mat', 'IMFvmd1Z')]\n",
        "}"
      ],
      "metadata": {
        "id": "WjUl5xBvgOVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_for_classification(classes):\n",
        "    X, y = [], []\n",
        "    for label, class_id in enumerate(classes):\n",
        "        file_info = file_info_dict[class_id]  # Get file paths and keys for each class\n",
        "        for file_path, key in file_info:\n",
        "            data = load_data_from_mat(file_path, key)\n",
        "            X.append(data)\n",
        "            y.append(np.array([label] * data.shape[0]))  # Assign the same label to all samples\n",
        "    X = np.concatenate(X)\n",
        "    y = np.concatenate(y)\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "lpUYLrPFgQJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cnn_lstm_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(LSTM(units=64, return_sequences=True))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(LSTM(units=32))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "fZS5r82FgoAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    return accuracy, recall, f1"
      ],
      "metadata": {
        "id": "bzMsmfkRhmzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_cnn_lstm_model(X_train, y_train, X_test, y_test, input_shape, num_classes):\n",
        " # Create the CNN-LSTM model\n",
        "    model = create_cnn_lstm_model(input_shape, num_classes)\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "    # Predict classes\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Compute additional metrics\n",
        "    accuracy, recall, f1 = compute_metrics(y_test, y_pred_classes)\n",
        "\n",
        "    # Print the metrics\n",
        "    print(f'Test Loss: {loss}')\n",
        "    print(f'Test Accuracy: {accuracy}')\n",
        "    print(f'Recall: {recall}')\n",
        "    print(f'F1 Score: {f1}')\n",
        "\n",
        "    return model, accuracy, recall, f1"
      ],
      "metadata": {
        "id": "wfLO1iguhse7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: AB vs CDE Classification\n",
        "classes = ['A', 'B', 'C', 'D', 'E']  # Use the appropriate subset of classes for each task\n",
        "X, y = prepare_data_for_classification(classes)\n",
        "\n",
        "# Preprocessing\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Get input shape and number of classes\n",
        "input_shape = (X_train.shape[1], 1)\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Reshape X to fit the CNN-LSTM model\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Train and evaluate\n",
        "model, accuracy, recall, f1 = train_and_evaluate_cnn_lstm_model(X_train, y_train, X_test, y_test, input_shape, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIkhng98hzX1",
        "outputId": "a6ff15b6-bd32-42e9-b775-9901655f2d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 66ms/step - accuracy: 0.5542 - loss: 0.9581 - val_accuracy: 0.7169 - val_loss: 0.6003\n",
            "Epoch 2/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 61ms/step - accuracy: 0.7304 - loss: 0.5709 - val_accuracy: 0.7769 - val_loss: 0.4436\n",
            "Epoch 3/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 66ms/step - accuracy: 0.7536 - loss: 0.4950 - val_accuracy: 0.7952 - val_loss: 0.4185\n",
            "Epoch 4/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 64ms/step - accuracy: 0.7703 - loss: 0.4556 - val_accuracy: 0.8223 - val_loss: 0.3937\n",
            "Epoch 5/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 62ms/step - accuracy: 0.8016 - loss: 0.4407 - val_accuracy: 0.8221 - val_loss: 0.3823\n",
            "Epoch 6/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 62ms/step - accuracy: 0.8183 - loss: 0.3931 - val_accuracy: 0.8245 - val_loss: 0.4119\n",
            "Epoch 7/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 60ms/step - accuracy: 0.8197 - loss: 0.3955 - val_accuracy: 0.8462 - val_loss: 0.3494\n",
            "Epoch 8/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 61ms/step - accuracy: 0.8218 - loss: 0.3785 - val_accuracy: 0.8399 - val_loss: 0.3760\n",
            "Epoch 9/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 62ms/step - accuracy: 0.8283 - loss: 0.3778 - val_accuracy: 0.8392 - val_loss: 0.3486\n",
            "Epoch 10/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 64ms/step - accuracy: 0.8345 - loss: 0.3641 - val_accuracy: 0.8528 - val_loss: 0.3310\n",
            "Epoch 11/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 60ms/step - accuracy: 0.8722 - loss: 0.3134 - val_accuracy: 0.8789 - val_loss: 0.3279\n",
            "Epoch 12/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 61ms/step - accuracy: 0.8965 - loss: 0.2770 - val_accuracy: 0.9180 - val_loss: 0.2252\n",
            "Epoch 13/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 60ms/step - accuracy: 0.9063 - loss: 0.2575 - val_accuracy: 0.9268 - val_loss: 0.1903\n",
            "Epoch 14/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 61ms/step - accuracy: 0.9263 - loss: 0.2155 - val_accuracy: 0.9314 - val_loss: 0.1835\n",
            "Epoch 15/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 61ms/step - accuracy: 0.9310 - loss: 0.1987 - val_accuracy: 0.9373 - val_loss: 0.1722\n",
            "Epoch 16/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 61ms/step - accuracy: 0.9346 - loss: 0.1839 - val_accuracy: 0.9448 - val_loss: 0.1541\n",
            "Epoch 17/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 60ms/step - accuracy: 0.9414 - loss: 0.1648 - val_accuracy: 0.9544 - val_loss: 0.1280\n",
            "Epoch 18/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 60ms/step - accuracy: 0.9468 - loss: 0.1701 - val_accuracy: 0.9602 - val_loss: 0.1168\n",
            "Epoch 19/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 63ms/step - accuracy: 0.9508 - loss: 0.1502 - val_accuracy: 0.9653 - val_loss: 0.1066\n",
            "Epoch 20/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 63ms/step - accuracy: 0.9603 - loss: 0.1184 - val_accuracy: 0.9627 - val_loss: 0.1086\n",
            "Epoch 21/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 62ms/step - accuracy: 0.9614 - loss: 0.1190 - val_accuracy: 0.9595 - val_loss: 0.1194\n",
            "Epoch 22/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 63ms/step - accuracy: 0.9647 - loss: 0.1112 - val_accuracy: 0.9566 - val_loss: 0.1383\n",
            "Epoch 23/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 65ms/step - accuracy: 0.9663 - loss: 0.1017 - val_accuracy: 0.9749 - val_loss: 0.0746\n",
            "Epoch 24/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 63ms/step - accuracy: 0.9702 - loss: 0.0915 - val_accuracy: 0.9624 - val_loss: 0.1151\n",
            "Epoch 25/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 60ms/step - accuracy: 0.9672 - loss: 0.1019 - val_accuracy: 0.9756 - val_loss: 0.0761\n",
            "Epoch 26/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 60ms/step - accuracy: 0.9747 - loss: 0.0764 - val_accuracy: 0.9751 - val_loss: 0.0719\n",
            "Epoch 27/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 60ms/step - accuracy: 0.9747 - loss: 0.0788 - val_accuracy: 0.9734 - val_loss: 0.0905\n",
            "Epoch 28/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 58ms/step - accuracy: 0.9788 - loss: 0.0715 - val_accuracy: 0.9756 - val_loss: 0.0724\n",
            "Epoch 29/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 60ms/step - accuracy: 0.9811 - loss: 0.0603 - val_accuracy: 0.9763 - val_loss: 0.0740\n",
            "Epoch 30/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 62ms/step - accuracy: 0.9817 - loss: 0.0559 - val_accuracy: 0.9822 - val_loss: 0.0598\n",
            "Epoch 31/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 60ms/step - accuracy: 0.9818 - loss: 0.0603 - val_accuracy: 0.9780 - val_loss: 0.0613\n",
            "Epoch 32/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 61ms/step - accuracy: 0.9836 - loss: 0.0533 - val_accuracy: 0.9800 - val_loss: 0.0635\n",
            "Epoch 33/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 60ms/step - accuracy: 0.9750 - loss: 0.0767 - val_accuracy: 0.9829 - val_loss: 0.0533\n",
            "Epoch 34/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 59ms/step - accuracy: 0.9884 - loss: 0.0368 - val_accuracy: 0.9812 - val_loss: 0.0654\n",
            "Epoch 35/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 59ms/step - accuracy: 0.9887 - loss: 0.0410 - val_accuracy: 0.9851 - val_loss: 0.0509\n",
            "Epoch 36/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 59ms/step - accuracy: 0.9874 - loss: 0.0426 - val_accuracy: 0.9805 - val_loss: 0.0627\n",
            "Epoch 37/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 61ms/step - accuracy: 0.9896 - loss: 0.0362 - val_accuracy: 0.9763 - val_loss: 0.0879\n",
            "Epoch 38/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 59ms/step - accuracy: 0.9861 - loss: 0.0434 - val_accuracy: 0.9863 - val_loss: 0.0560\n",
            "Epoch 39/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 59ms/step - accuracy: 0.9882 - loss: 0.0415 - val_accuracy: 0.9871 - val_loss: 0.0448\n",
            "Epoch 40/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 61ms/step - accuracy: 0.9862 - loss: 0.0463 - val_accuracy: 0.9866 - val_loss: 0.0480\n",
            "Epoch 41/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 61ms/step - accuracy: 0.9923 - loss: 0.0258 - val_accuracy: 0.9819 - val_loss: 0.0653\n",
            "Epoch 42/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 61ms/step - accuracy: 0.9856 - loss: 0.0453 - val_accuracy: 0.9885 - val_loss: 0.0391\n",
            "Epoch 43/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 62ms/step - accuracy: 0.9941 - loss: 0.0227 - val_accuracy: 0.9824 - val_loss: 0.0717\n",
            "Epoch 44/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 60ms/step - accuracy: 0.9928 - loss: 0.0238 - val_accuracy: 0.9793 - val_loss: 0.0752\n",
            "Epoch 45/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 60ms/step - accuracy: 0.9924 - loss: 0.0253 - val_accuracy: 0.9807 - val_loss: 0.0679\n",
            "Epoch 46/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 61ms/step - accuracy: 0.9918 - loss: 0.0282 - val_accuracy: 0.9876 - val_loss: 0.0452\n",
            "Epoch 47/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 62ms/step - accuracy: 0.9916 - loss: 0.0243 - val_accuracy: 0.9834 - val_loss: 0.0599\n",
            "Epoch 48/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 61ms/step - accuracy: 0.9895 - loss: 0.0307 - val_accuracy: 0.9895 - val_loss: 0.0466\n",
            "Epoch 49/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 60ms/step - accuracy: 0.9932 - loss: 0.0214 - val_accuracy: 0.9876 - val_loss: 0.0486\n",
            "Epoch 50/50\n",
            "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 64ms/step - accuracy: 0.9952 - loss: 0.0148 - val_accuracy: 0.9873 - val_loss: 0.0532\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9871 - loss: 0.0523\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step\n",
            "Test Loss: 0.05324581637978554\n",
            "Test Accuracy: 0.9873077861850135\n",
            "Recall: 0.9873077861850135\n",
            "F1 Score: 0.9873017375759543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AE Classification\n",
        "classes_ae = ['A', 'E']\n",
        "\n",
        "# Prepare data\n",
        "X_ae, y_ae = prepare_data_for_classification(classes_ae)\n",
        "\n",
        "# Merge and create new labels\n",
        "X = X_ae\n",
        "y = y_ae\n",
        "\n",
        "# Preprocessing\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Get input shape and number of classes\n",
        "input_shape = (X_train.shape[1], 1)\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Reshape X to fit the CNN-LSTM model\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Train and evaluate\n",
        "model, accuracy, recall, f1 = train_and_evaluate_cnn_lstm_model(X_train, y_train, X_test, y_test, input_shape, num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HogAI0--h1sw",
        "outputId": "dd29a100-2517-4955-8b23-de15409955cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 114ms/step - accuracy: 0.7086 - loss: 0.5395 - val_accuracy: 0.8554 - val_loss: 0.3246\n",
            "Epoch 2/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 63ms/step - accuracy: 0.8882 - loss: 0.2899 - val_accuracy: 0.8658 - val_loss: 0.2967\n",
            "Epoch 3/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 62ms/step - accuracy: 0.9318 - loss: 0.1951 - val_accuracy: 0.9323 - val_loss: 0.1590\n",
            "Epoch 4/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9508 - loss: 0.1320 - val_accuracy: 0.9152 - val_loss: 0.2145\n",
            "Epoch 5/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9594 - loss: 0.1108 - val_accuracy: 0.9707 - val_loss: 0.0827\n",
            "Epoch 6/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 52ms/step - accuracy: 0.9553 - loss: 0.1179 - val_accuracy: 0.9549 - val_loss: 0.1278\n",
            "Epoch 7/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 59ms/step - accuracy: 0.9583 - loss: 0.1190 - val_accuracy: 0.9719 - val_loss: 0.0744\n",
            "Epoch 8/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 52ms/step - accuracy: 0.9660 - loss: 0.0954 - val_accuracy: 0.9744 - val_loss: 0.0714\n",
            "Epoch 9/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 63ms/step - accuracy: 0.9731 - loss: 0.0824 - val_accuracy: 0.9768 - val_loss: 0.0738\n",
            "Epoch 10/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9632 - loss: 0.0964 - val_accuracy: 0.9713 - val_loss: 0.0745\n",
            "Epoch 11/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9758 - loss: 0.0743 - val_accuracy: 0.9744 - val_loss: 0.0733\n",
            "Epoch 12/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.9719 - loss: 0.0818 - val_accuracy: 0.9756 - val_loss: 0.0733\n",
            "Epoch 13/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.9695 - loss: 0.0912 - val_accuracy: 0.9732 - val_loss: 0.0831\n",
            "Epoch 14/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 63ms/step - accuracy: 0.9743 - loss: 0.0743 - val_accuracy: 0.9695 - val_loss: 0.0768\n",
            "Epoch 15/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 62ms/step - accuracy: 0.9781 - loss: 0.0706 - val_accuracy: 0.9762 - val_loss: 0.0680\n",
            "Epoch 16/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.9769 - loss: 0.0706 - val_accuracy: 0.9658 - val_loss: 0.0932\n",
            "Epoch 17/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9780 - loss: 0.0642 - val_accuracy: 0.9634 - val_loss: 0.1071\n",
            "Epoch 18/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.9673 - loss: 0.0878 - val_accuracy: 0.9707 - val_loss: 0.0747\n",
            "Epoch 19/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.9724 - loss: 0.0773 - val_accuracy: 0.9536 - val_loss: 0.1421\n",
            "Epoch 20/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9741 - loss: 0.0694 - val_accuracy: 0.9689 - val_loss: 0.0860\n",
            "Epoch 21/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.9822 - loss: 0.0531 - val_accuracy: 0.9817 - val_loss: 0.0549\n",
            "Epoch 22/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.9800 - loss: 0.0578 - val_accuracy: 0.9805 - val_loss: 0.0612\n",
            "Epoch 23/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - accuracy: 0.9797 - loss: 0.0633 - val_accuracy: 0.9799 - val_loss: 0.0502\n",
            "Epoch 24/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.9767 - loss: 0.0599 - val_accuracy: 0.9756 - val_loss: 0.0616\n",
            "Epoch 25/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.9842 - loss: 0.0453 - val_accuracy: 0.9774 - val_loss: 0.0632\n",
            "Epoch 26/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 51ms/step - accuracy: 0.9815 - loss: 0.0564 - val_accuracy: 0.9780 - val_loss: 0.0749\n",
            "Epoch 27/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 63ms/step - accuracy: 0.9803 - loss: 0.0577 - val_accuracy: 0.9866 - val_loss: 0.0445\n",
            "Epoch 28/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 62ms/step - accuracy: 0.9806 - loss: 0.0542 - val_accuracy: 0.9866 - val_loss: 0.0386\n",
            "Epoch 29/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.9848 - loss: 0.0424 - val_accuracy: 0.9811 - val_loss: 0.0540\n",
            "Epoch 30/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.9822 - loss: 0.0437 - val_accuracy: 0.9860 - val_loss: 0.0471\n",
            "Epoch 31/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.9868 - loss: 0.0360 - val_accuracy: 0.9780 - val_loss: 0.0621\n",
            "Epoch 32/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 53ms/step - accuracy: 0.9815 - loss: 0.0490 - val_accuracy: 0.9878 - val_loss: 0.0387\n",
            "Epoch 33/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - accuracy: 0.9890 - loss: 0.0350 - val_accuracy: 0.9805 - val_loss: 0.0544\n",
            "Epoch 34/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - accuracy: 0.9808 - loss: 0.0482 - val_accuracy: 0.9866 - val_loss: 0.0445\n",
            "Epoch 35/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.9893 - loss: 0.0297 - val_accuracy: 0.9884 - val_loss: 0.0438\n",
            "Epoch 36/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.9890 - loss: 0.0360 - val_accuracy: 0.9793 - val_loss: 0.0655\n",
            "Epoch 37/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 61ms/step - accuracy: 0.9895 - loss: 0.0332 - val_accuracy: 0.9866 - val_loss: 0.0375\n",
            "Epoch 38/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 64ms/step - accuracy: 0.9921 - loss: 0.0239 - val_accuracy: 0.9817 - val_loss: 0.0688\n",
            "Epoch 39/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 62ms/step - accuracy: 0.9839 - loss: 0.0441 - val_accuracy: 0.9872 - val_loss: 0.0482\n",
            "Epoch 40/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9897 - loss: 0.0298 - val_accuracy: 0.9841 - val_loss: 0.0418\n",
            "Epoch 41/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.9937 - loss: 0.0186 - val_accuracy: 0.9835 - val_loss: 0.0502\n",
            "Epoch 42/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.9914 - loss: 0.0240 - val_accuracy: 0.9860 - val_loss: 0.0428\n",
            "Epoch 43/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 52ms/step - accuracy: 0.9955 - loss: 0.0145 - val_accuracy: 0.9847 - val_loss: 0.0444\n",
            "Epoch 44/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9948 - loss: 0.0145 - val_accuracy: 0.9628 - val_loss: 0.0927\n",
            "Epoch 45/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 62ms/step - accuracy: 0.9835 - loss: 0.0425 - val_accuracy: 0.9860 - val_loss: 0.0499\n",
            "Epoch 46/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.9958 - loss: 0.0157 - val_accuracy: 0.9860 - val_loss: 0.0623\n",
            "Epoch 47/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.9949 - loss: 0.0152 - val_accuracy: 0.9896 - val_loss: 0.0355\n",
            "Epoch 48/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9960 - loss: 0.0140 - val_accuracy: 0.9829 - val_loss: 0.0524\n",
            "Epoch 49/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.9908 - loss: 0.0272 - val_accuracy: 0.9860 - val_loss: 0.0523\n",
            "Epoch 50/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.9924 - loss: 0.0239 - val_accuracy: 0.9872 - val_loss: 0.0373\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9868 - loss: 0.0395\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
            "Test Loss: 0.03726387396454811\n",
            "Test Accuracy: 0.9871873093349604\n",
            "Recall: 0.9871873093349604\n",
            "F1 Score: 0.9871878533623908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CE Classification\n",
        "classes_ce = ['C', 'E']\n",
        "\n",
        "# Prepare data\n",
        "X_ce, y_ce = prepare_data_for_classification(classes_ce)\n",
        "\n",
        "# Merge and create new labels\n",
        "X = X_ce\n",
        "y = y_ce\n",
        "\n",
        "# Preprocessing\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Get input shape and number of classes\n",
        "input_shape = (X_train.shape[1], 1)\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Reshape X to fit the CNN-LSTM model\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Train and evaluate\n",
        "model, accuracy, recall, f1 = train_and_evaluate_cnn_lstm_model(X_train, y_train, X_test, y_test, input_shape, num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h9V-U5IknON",
        "outputId": "9a57bbd7-8b12-4d92-98d9-0dfadfa5d46b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 60ms/step - accuracy: 0.6922 - loss: 0.5085 - val_accuracy: 0.9378 - val_loss: 0.1889\n",
            "Epoch 2/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.9552 - loss: 0.1258 - val_accuracy: 0.9426 - val_loss: 0.1442\n",
            "Epoch 3/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 63ms/step - accuracy: 0.9569 - loss: 0.1214 - val_accuracy: 0.9591 - val_loss: 0.0958\n",
            "Epoch 4/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 63ms/step - accuracy: 0.9589 - loss: 0.1223 - val_accuracy: 0.9634 - val_loss: 0.0967\n",
            "Epoch 5/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.9625 - loss: 0.1121 - val_accuracy: 0.9622 - val_loss: 0.1149\n",
            "Epoch 6/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 68ms/step - accuracy: 0.9564 - loss: 0.1268 - val_accuracy: 0.9622 - val_loss: 0.0918\n",
            "Epoch 7/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 73ms/step - accuracy: 0.9677 - loss: 0.0985 - val_accuracy: 0.9689 - val_loss: 0.0719\n",
            "Epoch 8/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step - accuracy: 0.9650 - loss: 0.0960 - val_accuracy: 0.9610 - val_loss: 0.0913\n",
            "Epoch 9/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.9705 - loss: 0.0909 - val_accuracy: 0.9750 - val_loss: 0.0752\n",
            "Epoch 10/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.9728 - loss: 0.0783 - val_accuracy: 0.9744 - val_loss: 0.0781\n",
            "Epoch 11/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.9793 - loss: 0.0623 - val_accuracy: 0.9805 - val_loss: 0.0528\n",
            "Epoch 12/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.9855 - loss: 0.0461 - val_accuracy: 0.9860 - val_loss: 0.0463\n",
            "Epoch 13/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 55ms/step - accuracy: 0.9798 - loss: 0.0585 - val_accuracy: 0.9817 - val_loss: 0.0426\n",
            "Epoch 14/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 61ms/step - accuracy: 0.9872 - loss: 0.0473 - val_accuracy: 0.9866 - val_loss: 0.0468\n",
            "Epoch 15/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.9856 - loss: 0.0468 - val_accuracy: 0.9847 - val_loss: 0.0455\n",
            "Epoch 16/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9873 - loss: 0.0420 - val_accuracy: 0.9756 - val_loss: 0.0595\n",
            "Epoch 17/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9854 - loss: 0.0421 - val_accuracy: 0.9719 - val_loss: 0.0931\n",
            "Epoch 18/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 56ms/step - accuracy: 0.9836 - loss: 0.0485 - val_accuracy: 0.9768 - val_loss: 0.0663\n",
            "Epoch 19/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - accuracy: 0.9853 - loss: 0.0434 - val_accuracy: 0.9847 - val_loss: 0.0371\n",
            "Epoch 20/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 52ms/step - accuracy: 0.9871 - loss: 0.0394 - val_accuracy: 0.9829 - val_loss: 0.0466\n",
            "Epoch 21/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9888 - loss: 0.0393 - val_accuracy: 0.9933 - val_loss: 0.0231\n",
            "Epoch 22/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9818 - loss: 0.0563 - val_accuracy: 0.9768 - val_loss: 0.0774\n",
            "Epoch 23/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9831 - loss: 0.0511 - val_accuracy: 0.9884 - val_loss: 0.0404\n",
            "Epoch 24/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9920 - loss: 0.0320 - val_accuracy: 0.9921 - val_loss: 0.0237\n",
            "Epoch 25/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.9931 - loss: 0.0260 - val_accuracy: 0.9927 - val_loss: 0.0311\n",
            "Epoch 26/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - accuracy: 0.9918 - loss: 0.0354 - val_accuracy: 0.9908 - val_loss: 0.0277\n",
            "Epoch 27/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9939 - loss: 0.0245 - val_accuracy: 0.9927 - val_loss: 0.0232\n",
            "Epoch 28/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.9895 - loss: 0.0337 - val_accuracy: 0.9939 - val_loss: 0.0259\n",
            "Epoch 29/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.9910 - loss: 0.0311 - val_accuracy: 0.9896 - val_loss: 0.0289\n",
            "Epoch 30/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9925 - loss: 0.0278 - val_accuracy: 0.9908 - val_loss: 0.0450\n",
            "Epoch 31/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 62ms/step - accuracy: 0.9897 - loss: 0.0403 - val_accuracy: 0.9902 - val_loss: 0.0287\n",
            "Epoch 32/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.9902 - loss: 0.0293 - val_accuracy: 0.9902 - val_loss: 0.0323\n",
            "Epoch 33/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9911 - loss: 0.0304 - val_accuracy: 0.9915 - val_loss: 0.0323\n",
            "Epoch 34/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 62ms/step - accuracy: 0.9962 - loss: 0.0142 - val_accuracy: 0.9908 - val_loss: 0.0352\n",
            "Epoch 35/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 66ms/step - accuracy: 0.9938 - loss: 0.0222 - val_accuracy: 0.9671 - val_loss: 0.1156\n",
            "Epoch 36/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.9926 - loss: 0.0286 - val_accuracy: 0.9933 - val_loss: 0.0255\n",
            "Epoch 37/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 65ms/step - accuracy: 0.9965 - loss: 0.0141 - val_accuracy: 0.9908 - val_loss: 0.0349\n",
            "Epoch 38/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 55ms/step - accuracy: 0.9954 - loss: 0.0151 - val_accuracy: 0.9933 - val_loss: 0.0256\n",
            "Epoch 39/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 61ms/step - accuracy: 0.9940 - loss: 0.0209 - val_accuracy: 0.9915 - val_loss: 0.0401\n",
            "Epoch 40/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 62ms/step - accuracy: 0.9948 - loss: 0.0265 - val_accuracy: 0.9908 - val_loss: 0.0406\n",
            "Epoch 41/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.9944 - loss: 0.0230 - val_accuracy: 0.9927 - val_loss: 0.0365\n",
            "Epoch 42/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9936 - loss: 0.0190 - val_accuracy: 0.9902 - val_loss: 0.0433\n",
            "Epoch 43/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.9906 - loss: 0.0340 - val_accuracy: 0.9902 - val_loss: 0.0252\n",
            "Epoch 44/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.9959 - loss: 0.0141 - val_accuracy: 0.9664 - val_loss: 0.1415\n",
            "Epoch 45/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9896 - loss: 0.0458 - val_accuracy: 0.9884 - val_loss: 0.0443\n",
            "Epoch 46/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 56ms/step - accuracy: 0.9965 - loss: 0.0118 - val_accuracy: 0.9774 - val_loss: 0.1088\n",
            "Epoch 47/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.9899 - loss: 0.0301 - val_accuracy: 0.9872 - val_loss: 0.0699\n",
            "Epoch 48/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.9894 - loss: 0.0304 - val_accuracy: 0.9927 - val_loss: 0.0278\n",
            "Epoch 49/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.9965 - loss: 0.0154 - val_accuracy: 0.9915 - val_loss: 0.0386\n",
            "Epoch 50/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - accuracy: 0.9860 - loss: 0.0432 - val_accuracy: 0.9823 - val_loss: 0.0497\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9900 - loss: 0.0335\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
            "Test Loss: 0.04969482868909836\n",
            "Test Accuracy: 0.9823062843197071\n",
            "Recall: 0.9823062843197071\n",
            "F1 Score: 0.9823070355956828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BE Classification\n",
        "classes_be = ['B', 'E']\n",
        "\n",
        "# Prepare data\n",
        "X_be, y_be = prepare_data_for_classification(classes_be)\n",
        "\n",
        "# Merge and create new labels\n",
        "X = X_be\n",
        "y = y_be\n",
        "\n",
        "# Preprocessing\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Get input shape and number of classes\n",
        "input_shape = (X_train.shape[1], 1)\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Reshape X to fit the CNN-LSTM model\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Train and evaluate\n",
        "model, accuracy, recall, f1 = train_and_evaluate_cnn_lstm_model(X_train, y_train, X_test, y_test, input_shape, num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AzfgwVwkpft",
        "outputId": "85cc798a-b657-4f89-8f28-794e210765d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 64ms/step - accuracy: 0.7457 - loss: 0.4592 - val_accuracy: 0.9500 - val_loss: 0.1349\n",
            "Epoch 2/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.9368 - loss: 0.1733 - val_accuracy: 0.9487 - val_loss: 0.1614\n",
            "Epoch 3/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.9396 - loss: 0.1794 - val_accuracy: 0.9262 - val_loss: 0.1911\n",
            "Epoch 4/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 61ms/step - accuracy: 0.9518 - loss: 0.1450 - val_accuracy: 0.9683 - val_loss: 0.1030\n",
            "Epoch 5/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9512 - loss: 0.1442 - val_accuracy: 0.9689 - val_loss: 0.0971\n",
            "Epoch 6/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.9636 - loss: 0.1154 - val_accuracy: 0.9677 - val_loss: 0.0955\n",
            "Epoch 7/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9560 - loss: 0.1249 - val_accuracy: 0.9518 - val_loss: 0.1210\n",
            "Epoch 8/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - accuracy: 0.9589 - loss: 0.1177 - val_accuracy: 0.9683 - val_loss: 0.0935\n",
            "Epoch 9/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.9593 - loss: 0.1106 - val_accuracy: 0.9585 - val_loss: 0.1088\n",
            "Epoch 10/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.9696 - loss: 0.0963 - val_accuracy: 0.9652 - val_loss: 0.0868\n",
            "Epoch 11/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.9596 - loss: 0.1110 - val_accuracy: 0.9793 - val_loss: 0.0741\n",
            "Epoch 12/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.9693 - loss: 0.0956 - val_accuracy: 0.9457 - val_loss: 0.1638\n",
            "Epoch 13/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - accuracy: 0.9617 - loss: 0.1138 - val_accuracy: 0.9591 - val_loss: 0.1048\n",
            "Epoch 14/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.9611 - loss: 0.1044 - val_accuracy: 0.9768 - val_loss: 0.0665\n",
            "Epoch 15/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.9764 - loss: 0.0805 - val_accuracy: 0.9799 - val_loss: 0.0581\n",
            "Epoch 16/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - accuracy: 0.9735 - loss: 0.0768 - val_accuracy: 0.9725 - val_loss: 0.0759\n",
            "Epoch 17/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 61ms/step - accuracy: 0.9763 - loss: 0.0670 - val_accuracy: 0.9768 - val_loss: 0.0616\n",
            "Epoch 18/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.9805 - loss: 0.0607 - val_accuracy: 0.9823 - val_loss: 0.0522\n",
            "Epoch 19/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 65ms/step - accuracy: 0.9789 - loss: 0.0605 - val_accuracy: 0.9786 - val_loss: 0.0527\n",
            "Epoch 20/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 54ms/step - accuracy: 0.9810 - loss: 0.0536 - val_accuracy: 0.9829 - val_loss: 0.0444\n",
            "Epoch 21/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 59ms/step - accuracy: 0.9775 - loss: 0.0625 - val_accuracy: 0.9719 - val_loss: 0.0630\n",
            "Epoch 22/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.9777 - loss: 0.0626 - val_accuracy: 0.9799 - val_loss: 0.0479\n",
            "Epoch 23/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.9847 - loss: 0.0493 - val_accuracy: 0.9835 - val_loss: 0.0489\n",
            "Epoch 24/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.9824 - loss: 0.0448 - val_accuracy: 0.9719 - val_loss: 0.0739\n",
            "Epoch 25/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9864 - loss: 0.0429 - val_accuracy: 0.9817 - val_loss: 0.0494\n",
            "Epoch 26/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.9810 - loss: 0.0556 - val_accuracy: 0.9829 - val_loss: 0.0462\n",
            "Epoch 27/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 62ms/step - accuracy: 0.9866 - loss: 0.0372 - val_accuracy: 0.9847 - val_loss: 0.0456\n",
            "Epoch 28/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 55ms/step - accuracy: 0.9881 - loss: 0.0411 - val_accuracy: 0.9841 - val_loss: 0.0427\n",
            "Epoch 29/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 61ms/step - accuracy: 0.9855 - loss: 0.0387 - val_accuracy: 0.9744 - val_loss: 0.0675\n",
            "Epoch 30/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 62ms/step - accuracy: 0.9869 - loss: 0.0347 - val_accuracy: 0.9860 - val_loss: 0.0408\n",
            "Epoch 31/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.9865 - loss: 0.0372 - val_accuracy: 0.9823 - val_loss: 0.0514\n",
            "Epoch 32/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.9832 - loss: 0.0542 - val_accuracy: 0.9799 - val_loss: 0.0565\n",
            "Epoch 33/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.9889 - loss: 0.0328 - val_accuracy: 0.9835 - val_loss: 0.0452\n",
            "Epoch 34/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9907 - loss: 0.0277 - val_accuracy: 0.9799 - val_loss: 0.0656\n",
            "Epoch 35/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 64ms/step - accuracy: 0.9885 - loss: 0.0294 - val_accuracy: 0.9854 - val_loss: 0.0405\n",
            "Epoch 36/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 59ms/step - accuracy: 0.9911 - loss: 0.0264 - val_accuracy: 0.9878 - val_loss: 0.0355\n",
            "Epoch 37/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.9915 - loss: 0.0284 - val_accuracy: 0.9872 - val_loss: 0.0388\n",
            "Epoch 38/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.9937 - loss: 0.0220 - val_accuracy: 0.9878 - val_loss: 0.0320\n",
            "Epoch 39/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9897 - loss: 0.0271 - val_accuracy: 0.9884 - val_loss: 0.0317\n",
            "Epoch 40/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9927 - loss: 0.0250 - val_accuracy: 0.9890 - val_loss: 0.0265\n",
            "Epoch 41/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9956 - loss: 0.0154 - val_accuracy: 0.9878 - val_loss: 0.0284\n",
            "Epoch 42/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 64ms/step - accuracy: 0.9950 - loss: 0.0155 - val_accuracy: 0.9872 - val_loss: 0.0423\n",
            "Epoch 43/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 63ms/step - accuracy: 0.9948 - loss: 0.0165 - val_accuracy: 0.9872 - val_loss: 0.0365\n",
            "Epoch 44/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 62ms/step - accuracy: 0.9952 - loss: 0.0143 - val_accuracy: 0.9884 - val_loss: 0.0289\n",
            "Epoch 45/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9961 - loss: 0.0180 - val_accuracy: 0.9902 - val_loss: 0.0264\n",
            "Epoch 46/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.9952 - loss: 0.0146 - val_accuracy: 0.9878 - val_loss: 0.0347\n",
            "Epoch 47/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 66ms/step - accuracy: 0.9942 - loss: 0.0164 - val_accuracy: 0.9890 - val_loss: 0.0351\n",
            "Epoch 48/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 56ms/step - accuracy: 0.9920 - loss: 0.0224 - val_accuracy: 0.9872 - val_loss: 0.0303\n",
            "Epoch 49/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9969 - loss: 0.0112 - val_accuracy: 0.9835 - val_loss: 0.0707\n",
            "Epoch 50/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.9967 - loss: 0.0123 - val_accuracy: 0.9890 - val_loss: 0.0345\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9875 - loss: 0.0292\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step\n",
            "Test Loss: 0.03453993424773216\n",
            "Test Accuracy: 0.9890176937156803\n",
            "Recall: 0.9890176937156803\n",
            "F1 Score: 0.9890182990826775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BD Classification\n",
        "classes_bd = ['B', 'D']\n",
        "\n",
        "# Prepare data\n",
        "X_bd, y_bd = prepare_data_for_classification(classes_bd)\n",
        "\n",
        "# Merge and create new labels\n",
        "X = X_bd\n",
        "y = y_bd\n",
        "\n",
        "# Preprocessing\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Get input shape and number of classes\n",
        "input_shape = (X_train.shape[1], 1)\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Reshape X to fit the CNN-LSTM model\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Train and evaluate\n",
        "model, accuracy, recall, f1 = train_and_evaluate_cnn_lstm_model(X_train, y_train, X_test, y_test, input_shape, num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoShxmbekrU9",
        "outputId": "a9064c78-6ce0-498c-dfcd-b59bea271848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 64ms/step - accuracy: 0.8818 - loss: 0.1871 - val_accuracy: 0.9963 - val_loss: 0.0247\n",
            "Epoch 2/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 64ms/step - accuracy: 0.9882 - loss: 0.0282 - val_accuracy: 1.0000 - val_loss: 5.4930e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 55ms/step - accuracy: 0.9999 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 2.8415e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.9996 - loss: 0.0026 - val_accuracy: 0.9988 - val_loss: 0.0087\n",
            "Epoch 5/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.9992 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 4.2928e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 61ms/step - accuracy: 0.9999 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 5.1330e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.9988 - val_loss: 0.0111\n",
            "Epoch 8/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.9994 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 3.9114e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 1.4641e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 3.8703e-04 - val_accuracy: 1.0000 - val_loss: 6.2440e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - accuracy: 0.9999 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 3.1400e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - accuracy: 0.9999 - loss: 6.4610e-04 - val_accuracy: 1.0000 - val_loss: 1.5108e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.9998 - loss: 8.6525e-04 - val_accuracy: 1.0000 - val_loss: 1.0165e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - accuracy: 0.9999 - loss: 9.0208e-04 - val_accuracy: 1.0000 - val_loss: 2.9356e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 5.8991e-04 - val_accuracy: 1.0000 - val_loss: 5.9124e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 3.3970e-04 - val_accuracy: 1.0000 - val_loss: 1.7762e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 1.9006e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 1.2387e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 4.5392e-06\n",
            "Epoch 20/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.9998 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 1.1660e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 2.4358e-04 - val_accuracy: 1.0000 - val_loss: 7.8063e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9999 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 1.4164e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9999 - loss: 7.2015e-04 - val_accuracy: 1.0000 - val_loss: 9.0068e-06\n",
            "Epoch 24/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.9997 - loss: 0.0025 - val_accuracy: 0.9994 - val_loss: 0.0054\n",
            "Epoch 25/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9999 - loss: 8.2891e-04 - val_accuracy: 1.0000 - val_loss: 2.5601e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.9998 - loss: 0.0022 - val_accuracy: 0.9994 - val_loss: 0.0023\n",
            "Epoch 27/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 5.9517e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 2.6449e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9994 - val_loss: 0.0044\n",
            "Epoch 30/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 6.4497e-04 - val_accuracy: 1.0000 - val_loss: 8.1009e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 64ms/step - accuracy: 0.9933 - loss: 0.0145 - val_accuracy: 1.0000 - val_loss: 2.8455e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 55ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 9.2923e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - accuracy: 0.9999 - loss: 9.8761e-04 - val_accuracy: 1.0000 - val_loss: 1.0494e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 55ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 8.6307e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - accuracy: 0.9998 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 5.2137e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9991 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 5.1605e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - accuracy: 0.9999 - loss: 9.7188e-04 - val_accuracy: 1.0000 - val_loss: 7.3408e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.9998 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 1.8678e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 1.7712e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 62ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 1.5104e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.9999 - loss: 8.2065e-04 - val_accuracy: 1.0000 - val_loss: 5.8172e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.9999 - loss: 5.4669e-04 - val_accuracy: 1.0000 - val_loss: 2.3170e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.9999 - loss: 7.3114e-04 - val_accuracy: 1.0000 - val_loss: 2.7142e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 63ms/step - accuracy: 0.9999 - loss: 4.2264e-04 - val_accuracy: 1.0000 - val_loss: 4.1754e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.9998 - loss: 4.7162e-04 - val_accuracy: 1.0000 - val_loss: 1.5995e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 61ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 1.5658e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 1.5773e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 65ms/step - accuracy: 0.9999 - loss: 4.0560e-04 - val_accuracy: 1.0000 - val_loss: 1.2501e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 56ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 1.3557e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 4.8321e-05 - val_accuracy: 1.0000 - val_loss: 1.1261e-04\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 9.6979e-05\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
            "Test Loss: 0.00011260700557613745\n",
            "Test Accuracy: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AC Classification\n",
        "classes_ac = ['A', 'C']\n",
        "\n",
        "# Prepare data\n",
        "X_ac, y_ac = prepare_data_for_classification(classes_ac)\n",
        "\n",
        "# Merge and create new labels\n",
        "X = X_ac\n",
        "y = y_ac\n",
        "\n",
        "# Preprocessing\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Get input shape and number of classes\n",
        "input_shape = (X_train.shape[1], 1)\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Reshape X to fit the CNN-LSTM model\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Train and evaluate\n",
        "model, accuracy, recall, f1 = train_and_evaluate_cnn_lstm_model(X_train, y_train, X_test, y_test, input_shape, num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6WB1VlZktGN",
        "outputId": "5ce9b6a9-21f5-4622-d9b3-fbfd04b40af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - accuracy: 0.7856 - loss: 0.3819 - val_accuracy: 0.9494 - val_loss: 0.1511\n",
            "Epoch 2/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 63ms/step - accuracy: 0.9779 - loss: 0.0778 - val_accuracy: 0.9915 - val_loss: 0.0315\n",
            "Epoch 3/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 65ms/step - accuracy: 0.9914 - loss: 0.0334 - val_accuracy: 0.9939 - val_loss: 0.0262\n",
            "Epoch 4/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 58ms/step - accuracy: 0.9879 - loss: 0.0443 - val_accuracy: 0.9878 - val_loss: 0.0385\n",
            "Epoch 5/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - accuracy: 0.9919 - loss: 0.0325 - val_accuracy: 0.9951 - val_loss: 0.0257\n",
            "Epoch 6/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.9963 - loss: 0.0165 - val_accuracy: 0.9957 - val_loss: 0.0201\n",
            "Epoch 7/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.9949 - loss: 0.0176 - val_accuracy: 0.9957 - val_loss: 0.0217\n",
            "Epoch 8/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 59ms/step - accuracy: 0.9927 - loss: 0.0243 - val_accuracy: 0.9957 - val_loss: 0.0198\n",
            "Epoch 9/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.9954 - loss: 0.0168 - val_accuracy: 0.9963 - val_loss: 0.0174\n",
            "Epoch 10/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.9910 - loss: 0.0244 - val_accuracy: 0.9963 - val_loss: 0.0182\n",
            "Epoch 11/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.9958 - loss: 0.0167 - val_accuracy: 0.9939 - val_loss: 0.0232\n",
            "Epoch 12/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - accuracy: 0.9971 - loss: 0.0125 - val_accuracy: 0.9969 - val_loss: 0.0184\n",
            "Epoch 13/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 51ms/step - accuracy: 0.9973 - loss: 0.0093 - val_accuracy: 0.9957 - val_loss: 0.0138\n",
            "Epoch 14/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.9974 - loss: 0.0112 - val_accuracy: 0.9860 - val_loss: 0.0681\n",
            "Epoch 15/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 53ms/step - accuracy: 0.9933 - loss: 0.0220 - val_accuracy: 0.9969 - val_loss: 0.0168\n",
            "Epoch 16/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - accuracy: 0.9975 - loss: 0.0115 - val_accuracy: 0.9890 - val_loss: 0.0363\n",
            "Epoch 17/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.9953 - loss: 0.0199 - val_accuracy: 0.9945 - val_loss: 0.0267\n",
            "Epoch 18/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9931 - loss: 0.0258 - val_accuracy: 0.9890 - val_loss: 0.0353\n",
            "Epoch 19/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.9949 - loss: 0.0189 - val_accuracy: 0.9969 - val_loss: 0.0175\n",
            "Epoch 20/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 64ms/step - accuracy: 0.9972 - loss: 0.0106 - val_accuracy: 0.9774 - val_loss: 0.0890\n",
            "Epoch 21/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 56ms/step - accuracy: 0.9978 - loss: 0.0092 - val_accuracy: 0.9957 - val_loss: 0.0166\n",
            "Epoch 22/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.9977 - loss: 0.0101 - val_accuracy: 0.9951 - val_loss: 0.0194\n",
            "Epoch 23/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 62ms/step - accuracy: 0.9965 - loss: 0.0146 - val_accuracy: 0.9982 - val_loss: 0.0123\n",
            "Epoch 24/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9978 - loss: 0.0088 - val_accuracy: 0.9945 - val_loss: 0.0323\n",
            "Epoch 25/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - accuracy: 0.9969 - loss: 0.0132 - val_accuracy: 0.9976 - val_loss: 0.0184\n",
            "Epoch 26/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 63ms/step - accuracy: 0.9993 - loss: 0.0047 - val_accuracy: 0.9939 - val_loss: 0.0165\n",
            "Epoch 27/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9980 - loss: 0.0087 - val_accuracy: 0.9982 - val_loss: 0.0049\n",
            "Epoch 28/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 65ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
            "Epoch 29/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 53ms/step - accuracy: 0.9980 - loss: 0.0080 - val_accuracy: 0.9933 - val_loss: 0.0344\n",
            "Epoch 30/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 62ms/step - accuracy: 0.9985 - loss: 0.0049 - val_accuracy: 0.9982 - val_loss: 0.0047\n",
            "Epoch 31/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - accuracy: 0.9984 - loss: 0.0055 - val_accuracy: 0.9921 - val_loss: 0.0553\n",
            "Epoch 32/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 64ms/step - accuracy: 0.9966 - loss: 0.0112 - val_accuracy: 0.9976 - val_loss: 0.0214\n",
            "Epoch 33/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 66ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9994 - val_loss: 0.0019\n",
            "Epoch 34/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 68ms/step - accuracy: 0.9971 - loss: 0.0094 - val_accuracy: 0.9951 - val_loss: 0.0152\n",
            "Epoch 35/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 62ms/step - accuracy: 0.9984 - loss: 0.0046 - val_accuracy: 0.9982 - val_loss: 0.0094\n",
            "Epoch 36/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9969 - val_loss: 0.0078\n",
            "Epoch 37/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 68ms/step - accuracy: 0.9980 - loss: 0.0074 - val_accuracy: 0.9969 - val_loss: 0.0049\n",
            "Epoch 38/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.9993 - loss: 0.0048 - val_accuracy: 0.9988 - val_loss: 0.0043\n",
            "Epoch 39/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 63ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.9982 - val_loss: 0.0077\n",
            "Epoch 40/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9982 - val_loss: 0.0052\n",
            "Epoch 41/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9980 - loss: 0.0085 - val_accuracy: 0.9988 - val_loss: 0.0024\n",
            "Epoch 42/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 65ms/step - accuracy: 0.9988 - loss: 0.0061 - val_accuracy: 0.9939 - val_loss: 0.0439\n",
            "Epoch 43/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - accuracy: 0.9974 - loss: 0.0102 - val_accuracy: 0.9988 - val_loss: 0.0026\n",
            "Epoch 44/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 8.8616e-04 - val_accuracy: 0.9994 - val_loss: 0.0016\n",
            "Epoch 45/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 63ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 6.2946e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 62ms/step - accuracy: 0.9999 - loss: 9.1667e-04 - val_accuracy: 0.9988 - val_loss: 0.0020\n",
            "Epoch 47/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - accuracy: 0.9997 - loss: 0.0028 - val_accuracy: 0.9994 - val_loss: 9.3199e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 57ms/step - accuracy: 0.9998 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 7.7790e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 65ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.9994 - val_loss: 9.3357e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 57ms/step - accuracy: 0.9998 - loss: 0.0020 - val_accuracy: 0.9988 - val_loss: 0.0014\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9997 - loss: 4.7185e-04\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step\n",
            "Test Loss: 0.0013882564380764961\n",
            "Test Accuracy: 0.9987797437461867\n",
            "Recall: 0.9987797437461867\n",
            "F1 Score: 0.9987797791976124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PYkZ5iLRku_5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}