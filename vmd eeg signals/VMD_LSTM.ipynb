{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Of7LlOGkZUD-"
      },
      "outputs": [],
      "source": [
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Flatten\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b-QQ9EeZiaw"
      },
      "outputs": [],
      "source": [
        "def load_data_from_mat(file_path, key):\n",
        "    data = loadmat(file_path)\n",
        "    return data[key]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Drq5pALiZlcD"
      },
      "outputs": [],
      "source": [
        "# Define paths and keys for each class\n",
        "file_info_dict = {\n",
        "    'A': [('/content/drive/MyDrive/emdvmd/VMDF.mat', 'IMFvmd1F')],\n",
        "    'B': [('/content/drive/MyDrive/emdvmd/VMDN.mat', 'IMFvmd1N')],\n",
        "    'C': [('/content/drive/MyDrive/emdvmd/VMDO.mat', 'IMFvmd1O')],\n",
        "    'D': [('/content/drive/MyDrive/emdvmd/VMDS.mat', 'IMFvmd1S')],\n",
        "    'E': [('/content/drive/MyDrive/emdvmd/VMDZ.mat', 'IMFvmd1Z')]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06dtFWcYZ2RN"
      },
      "outputs": [],
      "source": [
        "def prepare_data_for_classification(classes):\n",
        "    X, y = [], []\n",
        "    for label, class_id in enumerate(classes):\n",
        "        file_info = file_info_dict[class_id]  # Get file paths and keys for each class\n",
        "        for file_path, key in file_info:\n",
        "            data = load_data_from_mat(file_path, key)\n",
        "            X.append(data)\n",
        "            y.append(np.array([label] * data.shape[0]))  # Assign the same label to all samples\n",
        "    X = np.concatenate(X)\n",
        "    y = np.concatenate(y)\n",
        "    return X, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXYCSDKuZ5h8"
      },
      "outputs": [],
      "source": [
        "def create_lstm_model(input_shape, lstm_units1, lstm_units2, dense_units, output_units, dropout_rate):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=lstm_units1, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(Dropout(rate=dropout_rate))\n",
        "    model.add(LSTM(units=lstm_units2))\n",
        "    model.add(Dropout(rate=dropout_rate))\n",
        "    model.add(Dense(units=dense_units, activation='relu'))\n",
        "    model.add(Dense(units=output_units, activation='softmax'))\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQ75SbgiZ8Qc"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(y_true, y_pred):\n",
        "    y_true = np.argmax(y_true, axis=1)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    sensitivity = recall_score(y_true, y_pred, average='macro')\n",
        "    specificity = recall_score(y_true, y_pred, average='macro', labels=[0, 1])\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    return accuracy, sensitivity, specificity, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwuX29xRZ_3c"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_lstm_model(X_train, y_train, X_test, y_test, lstm_units1, lstm_units2, dense_units, dropout_rate, batch_size, epochs):\n",
        "    model = create_lstm_model((X_train.shape[1], 1), lstm_units1, lstm_units2, dense_units, y_train.shape[1], dropout_rate)\n",
        "    history = model.fit(X_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "    y_pred = model.predict(X_test)\n",
        "    score = model.evaluate(X_test, y_test, verbose=1)\n",
        "    accuracy, sensitivity, specificity, f1 = compute_metrics(y_test, y_pred)\n",
        "    print(f'Test loss: {score[0]}')\n",
        "    print(f'Test accuracy: {accuracy}')\n",
        "    print(f'Sensitivity (Recall): {sensitivity}')\n",
        "    print(f'Specificity: {specificity}')\n",
        "    print(f'F1 Score: {f1}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFdQKggBaKgL"
      },
      "source": [
        "Classification A-B vs. C-D-E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O-ytXXCaCiI",
        "outputId": "c00ba565-d740-4b42-ee8d-6adf01ccb580"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 232ms/step - accuracy: 0.7146 - loss: 0.5397 - val_accuracy: 0.9002 - val_loss: 0.2517\n",
            "Epoch 2/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 218ms/step - accuracy: 0.8833 - loss: 0.2836 - val_accuracy: 0.6056 - val_loss: 0.6712\n",
            "Epoch 3/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 209ms/step - accuracy: 0.5969 - loss: 0.6754 - val_accuracy: 0.6056 - val_loss: 0.6712\n",
            "Epoch 4/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 217ms/step - accuracy: 0.5976 - loss: 0.6733 - val_accuracy: 0.6056 - val_loss: 0.6718\n",
            "Epoch 5/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 209ms/step - accuracy: 0.5993 - loss: 0.6698 - val_accuracy: 0.6046 - val_loss: 0.6115\n",
            "Epoch 6/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 216ms/step - accuracy: 0.7272 - loss: 0.5055 - val_accuracy: 0.8819 - val_loss: 0.2643\n",
            "Epoch 7/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 222ms/step - accuracy: 0.9152 - loss: 0.2220 - val_accuracy: 0.9070 - val_loss: 0.2151\n",
            "Epoch 8/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 241ms/step - accuracy: 0.9348 - loss: 0.1837 - val_accuracy: 0.9378 - val_loss: 0.1558\n",
            "Epoch 9/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 217ms/step - accuracy: 0.9464 - loss: 0.1377 - val_accuracy: 0.9512 - val_loss: 0.1250\n",
            "Epoch 10/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 214ms/step - accuracy: 0.9559 - loss: 0.1267 - val_accuracy: 0.9582 - val_loss: 0.1086\n",
            "Epoch 11/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 214ms/step - accuracy: 0.9604 - loss: 0.1028 - val_accuracy: 0.9524 - val_loss: 0.1205\n",
            "Epoch 12/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 210ms/step - accuracy: 0.9601 - loss: 0.1061 - val_accuracy: 0.9594 - val_loss: 0.1006\n",
            "Epoch 13/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 208ms/step - accuracy: 0.9653 - loss: 0.0954 - val_accuracy: 0.9606 - val_loss: 0.1149\n",
            "Epoch 14/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 208ms/step - accuracy: 0.9625 - loss: 0.0957 - val_accuracy: 0.9671 - val_loss: 0.0947\n",
            "Epoch 15/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 204ms/step - accuracy: 0.9695 - loss: 0.0801 - val_accuracy: 0.9680 - val_loss: 0.0909\n",
            "Epoch 16/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 215ms/step - accuracy: 0.9693 - loss: 0.0820 - val_accuracy: 0.9667 - val_loss: 0.0932\n",
            "Epoch 17/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 210ms/step - accuracy: 0.9703 - loss: 0.0779 - val_accuracy: 0.9646 - val_loss: 0.0904\n",
            "Epoch 18/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 210ms/step - accuracy: 0.9711 - loss: 0.0755 - val_accuracy: 0.9759 - val_loss: 0.0713\n",
            "Epoch 19/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 211ms/step - accuracy: 0.9770 - loss: 0.0637 - val_accuracy: 0.9750 - val_loss: 0.0773\n",
            "Epoch 20/20\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 208ms/step - accuracy: 0.9792 - loss: 0.0604 - val_accuracy: 0.9771 - val_loss: 0.0705\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 78ms/step - accuracy: 0.9804 - loss: 0.0525\n",
            "Test loss: 0.05765077844262123\n",
            "Test accuracy: 0.9794971930680986\n",
            "Sensitivity (Recall): 0.9762636726561782\n",
            "Specificity: 0.9762636726561782\n",
            "F1 Score: 0.9785220004892881\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data for classes A-B vs. C-D-E\n",
        "classes_ab = ['A', 'B']\n",
        "classes_cde = ['C', 'D', 'E']\n",
        "\n",
        "X_ab, y_ab = prepare_data_for_classification(classes_ab)\n",
        "X_cde, y_cde = prepare_data_for_classification(classes_cde)\n",
        "\n",
        "# Merge and create new labels\n",
        "X = np.concatenate([X_ab, X_cde])\n",
        "y = np.concatenate([np.zeros(len(y_ab)), np.ones(len(y_cde))])  # 0 for A-B, 1 for C-D-E\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape data for LSTM\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# Encode labels\n",
        "y = y.astype(int)\n",
        "y = np.eye(len(np.unique(y)))[y]  # One-hot encode the labels\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate the LSTM model\n",
        "train_and_evaluate_lstm_model(X_train, y_train, X_test, y_test, lstm_units1=128, lstm_units2=64, dense_units=32, dropout_rate=0.3, batch_size=32, epochs=20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXbr4cs8ahGV"
      },
      "source": [
        "Classification A vs. E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RQDl6ylafXy",
        "outputId": "34023605-3b92-4ad8-f996-413df312c33e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 260ms/step - accuracy: 0.5735 - loss: 0.6459 - val_accuracy: 0.8459 - val_loss: 0.3640\n",
            "Epoch 2/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 254ms/step - accuracy: 0.8411 - loss: 0.3853 - val_accuracy: 0.8757 - val_loss: 0.3216\n",
            "Epoch 3/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 245ms/step - accuracy: 0.9086 - loss: 0.2530 - val_accuracy: 0.9275 - val_loss: 0.2106\n",
            "Epoch 4/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 246ms/step - accuracy: 0.9305 - loss: 0.1905 - val_accuracy: 0.9397 - val_loss: 0.1698\n",
            "Epoch 5/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 234ms/step - accuracy: 0.9410 - loss: 0.1681 - val_accuracy: 0.9481 - val_loss: 0.1596\n",
            "Epoch 6/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 250ms/step - accuracy: 0.9421 - loss: 0.1617 - val_accuracy: 0.9474 - val_loss: 0.1628\n",
            "Epoch 7/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 250ms/step - accuracy: 0.9475 - loss: 0.1500 - val_accuracy: 0.9161 - val_loss: 0.2235\n",
            "Epoch 8/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 239ms/step - accuracy: 0.9443 - loss: 0.1658 - val_accuracy: 0.9619 - val_loss: 0.1262\n",
            "Epoch 9/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 236ms/step - accuracy: 0.9550 - loss: 0.1363 - val_accuracy: 0.9695 - val_loss: 0.0886\n",
            "Epoch 10/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 253ms/step - accuracy: 0.9662 - loss: 0.0911 - val_accuracy: 0.9649 - val_loss: 0.0969\n",
            "Epoch 11/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 249ms/step - accuracy: 0.9645 - loss: 0.1012 - val_accuracy: 0.9725 - val_loss: 0.0827\n",
            "Epoch 12/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 238ms/step - accuracy: 0.9658 - loss: 0.0965 - val_accuracy: 0.9695 - val_loss: 0.0945\n",
            "Epoch 13/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 250ms/step - accuracy: 0.9677 - loss: 0.0907 - val_accuracy: 0.9718 - val_loss: 0.0872\n",
            "Epoch 14/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 250ms/step - accuracy: 0.9659 - loss: 0.0957 - val_accuracy: 0.9458 - val_loss: 0.1281\n",
            "Epoch 15/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 238ms/step - accuracy: 0.9683 - loss: 0.0816 - val_accuracy: 0.9741 - val_loss: 0.0808\n",
            "Epoch 16/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 242ms/step - accuracy: 0.9712 - loss: 0.0816 - val_accuracy: 0.9764 - val_loss: 0.0696\n",
            "Epoch 17/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 245ms/step - accuracy: 0.9754 - loss: 0.0729 - val_accuracy: 0.9764 - val_loss: 0.0693\n",
            "Epoch 18/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 264ms/step - accuracy: 0.9748 - loss: 0.0686 - val_accuracy: 0.9764 - val_loss: 0.0681\n",
            "Epoch 19/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 246ms/step - accuracy: 0.9750 - loss: 0.0715 - val_accuracy: 0.9840 - val_loss: 0.0609\n",
            "Epoch 20/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 227ms/step - accuracy: 0.9781 - loss: 0.0593 - val_accuracy: 0.9771 - val_loss: 0.0684\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.9793 - loss: 0.0511\n",
            "Test loss: 0.06507231295108795\n",
            "Test accuracy: 0.9774252593044539\n",
            "Sensitivity (Recall): 0.9776402050181775\n",
            "Specificity: 0.9776402050181775\n",
            "F1 Score: 0.9774195770475993\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data for classes A vs. E\n",
        "classes_a = ['A']\n",
        "classes_e = ['E']\n",
        "\n",
        "X_a, y_a = prepare_data_for_classification(classes_a)\n",
        "X_e, y_e = prepare_data_for_classification(classes_e)\n",
        "\n",
        "# Merge and create new labels\n",
        "X = np.concatenate([X_a, X_e])\n",
        "y = np.concatenate([np.zeros(len(y_a)), np.ones(len(y_e))])  # 0 for A, 1 for E\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape data for LSTM\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# Encode labels\n",
        "y = y.astype(int)\n",
        "y = np.eye(len(np.unique(y)))[y]  # One-hot encode the labels\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate the LSTM model\n",
        "train_and_evaluate_lstm_model(X_train, y_train, X_test, y_test, lstm_units1=128, lstm_units2=64, dense_units=32, dropout_rate=0.3, batch_size=32, epochs=20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhvdmsF7aoNx"
      },
      "source": [
        "Classification B vs. E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OSMOrQmaVe2"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess data for classes B vs. E\n",
        "classes_b = ['B']\n",
        "classes_e = ['E']\n",
        "\n",
        "X_b, y_b = prepare_data_for_classification(classes_b)\n",
        "X_e, y_e = prepare_data_for_classification(classes_e)\n",
        "\n",
        "# Merge and create new labels\n",
        "X = np.concatenate([X_b, X_e])\n",
        "y = np.concatenate([np.zeros(len(y_b)), np.ones(len(y_e))])  # 0 for B, 1 for E\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape data for LSTM\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# Encode labels\n",
        "y = y.astype(int)\n",
        "y = np.eye(len(np.unique(y)))[y]  # One-hot encode the labels\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate the LSTM model\n",
        "train_and_evaluate_lstm_model(X_train, y_train, X_test, y_test, lstm_units1=128, lstm_units2=64, dense_units=32, dropout_rate=0.3, batch_size=32, epochs=20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTB2mocma43Y"
      },
      "source": [
        "Classification B vs. D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1-eg3yja1SU",
        "outputId": "18b67f5d-eb21-4a19-94f0-6f76aedaa695"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 350ms/step - accuracy: 0.6448 - loss: 0.6672 - val_accuracy: 0.5065 - val_loss: 0.6929\n",
            "Epoch 2/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 237ms/step - accuracy: 0.4883 - loss: 0.6973 - val_accuracy: 0.5149 - val_loss: 0.6924\n",
            "Epoch 3/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 225ms/step - accuracy: 0.5195 - loss: 0.6944 - val_accuracy: 0.5149 - val_loss: 0.6922\n",
            "Epoch 4/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 232ms/step - accuracy: 0.4974 - loss: 0.6945 - val_accuracy: 0.4851 - val_loss: 0.6954\n",
            "Epoch 5/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 228ms/step - accuracy: 0.5360 - loss: 0.6865 - val_accuracy: 0.9634 - val_loss: 0.1467\n",
            "Epoch 6/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 231ms/step - accuracy: 0.9842 - loss: 0.0733 - val_accuracy: 0.9992 - val_loss: 0.0067\n",
            "Epoch 7/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 240ms/step - accuracy: 0.9969 - loss: 0.0192 - val_accuracy: 1.0000 - val_loss: 6.0613e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 224ms/step - accuracy: 0.9982 - loss: 0.0140 - val_accuracy: 0.9992 - val_loss: 0.0058\n",
            "Epoch 9/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 247ms/step - accuracy: 0.9973 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 5.5206e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 259ms/step - accuracy: 0.9993 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 5.1062e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 236ms/step - accuracy: 0.9995 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 2.5987e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 256ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 8.4813e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 241ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 3.5917e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 234ms/step - accuracy: 0.9987 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 1.1921e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 245ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0050\n",
            "Epoch 16/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 223ms/step - accuracy: 0.9999 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 5.5608e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 232ms/step - accuracy: 0.9993 - loss: 0.0035 - val_accuracy: 0.9992 - val_loss: 0.0035\n",
            "Epoch 18/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 254ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 1.4251e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 228ms/step - accuracy: 0.9999 - loss: 6.2845e-04 - val_accuracy: 1.0000 - val_loss: 4.8306e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 240ms/step - accuracy: 0.9992 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 1.0722e-04\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 121ms/step\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.9988 - loss: 0.0069\n",
            "Test loss: 0.003452151548117399\n",
            "Test accuracy: 0.9993898718730934\n",
            "Sensitivity (Recall): 0.9994047619047619\n",
            "Specificity: 0.9994047619047619\n",
            "F1 Score: 0.9993895082580275\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data for classes B vs. D\n",
        "classes_b = ['B']\n",
        "classes_d = ['D']\n",
        "\n",
        "X_b, y_b = prepare_data_for_classification(classes_b)\n",
        "X_d, y_d = prepare_data_for_classification(classes_d)\n",
        "\n",
        "# Merge and create new labels\n",
        "X = np.concatenate([X_b, X_d])\n",
        "y = np.concatenate([np.zeros(len(y_b)), np.ones(len(y_d))])  # 0 for B, 1 for D\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape data for LSTM\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# Encode labels\n",
        "y = y.astype(int)\n",
        "y = np.eye(len(np.unique(y)))[y]  # One-hot encode the labels\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate the LSTM model\n",
        "train_and_evaluate_lstm_model(X_train, y_train, X_test, y_test, lstm_units1=128, lstm_units2=64, dense_units=32, dropout_rate=0.3, batch_size=32, epochs=20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcZbPzOga-yB"
      },
      "source": [
        "Classification A vs. C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4t_bc7lJa6-i"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess data for classes A vs. C\n",
        "classes_a = ['A']\n",
        "classes_c = ['C']\n",
        "\n",
        "X_a, y_a = prepare_data_for_classification(classes_a)\n",
        "X_c, y_c = prepare_data_for_classification(classes_c)\n",
        "\n",
        "# Merge and create new labels\n",
        "X = np.concatenate([X_a, X_c])\n",
        "y = np.concatenate([np.zeros(len(y_a)), np.ones(len(y_c))])  # 0 for A, 1 for C\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape data for LSTM\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# Encode labels\n",
        "y = y.astype(int)\n",
        "y = np.eye(len(np.unique(y)))[y]  # One-hot encode the labels\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate the LSTM model\n",
        "train_and_evaluate_lstm_model(X_train, y_train, X_test, y_test, lstm_units1=128, lstm_units2=64, dense_units=32, dropout_rate=0.3, batch_size=32, epochs=20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b_oQkZNbSVZ"
      },
      "source": [
        "Classification C vs. E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psErpnTWbBR0"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess data for classes C vs. E\n",
        "classes_c = ['C']\n",
        "classes_e = ['E']\n",
        "\n",
        "X_c, y_c = prepare_data_for_classification(classes_c)\n",
        "X_e, y_e = prepare_data_for_classification(classes_e)\n",
        "\n",
        "# Merge and create new labels\n",
        "X = np.concatenate([X_c, X_e])\n",
        "y = np.concatenate([np.zeros(len(y_c)), np.ones(len(y_e))])  # 0 for C, 1 for E\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape data for LSTM\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# Encode labels\n",
        "y = y.astype(int)\n",
        "y = np.eye(len(np.unique(y)))[y]  # One-hot encode the labels\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate the LSTM model\n",
        "train_and_evaluate_lstm_model(X_train, y_train, X_test, y_test, lstm_units1=128, lstm_units2=64, dense_units=32, dropout_rate=0.3, batch_size=32, epochs=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFJJg5UZbivH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}